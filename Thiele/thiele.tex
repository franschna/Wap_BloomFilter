\section{Probleme von Bloom-Filtern und Lösungen}
\subsection{Das Löschen von Elementen}
Der klassische Bloom-Filter besitzt unter anderem die Einschränkung, dass er das Löschen von Elementen nicht unterstützt. Möchte man ein Element entfernen, liegt es zunächst nahe, die entsprechenden Bits im Bit-Array wieder auf 0 zu setzen. Genau hier entsteht jedoch ein fundamentales Problem. Mehrere Elemente können auf dieselbe Position im Bit-Array hashen. Wird ein Bit zurückgesetzt, entfernt man daher nicht nur das gewünschte Element, sondern gleichzeitig auch alle anderen Elemente, die an dieser Position gespeichert wurden. Das eigentliche Element ist zwar entfernt, aber andere Elemente gelten nun ebenfalls als nicht mehr vorhanden, obwohl sie eigentlich noch im Filter sein sollten.

Eine Lösung für dieses Problem ist der Counting Bloom Filter. \cite{bloomThiele} Das Grundprinzip beim Einfügen bleibt dabei gleich wie beim klassischen Bloom-Filter. Der Unterschied besteht darin, dass man an jeder Position nicht nur ein einzelnes Bit speichert, sondern einen kleinen Zähler. Dieser Zähler wird beim Einfügen eines Elements um 1 erhöht und beim Löschen wieder um 1 verringert. Typischerweise sind diese Zähler 4 Bit groß und können somit Werte von 0 bis 15 speichern. Dadurch wird es möglich, Elemente sicher zu löschen, ohne andere Einträge unbeabsichtigt zu beeinflussen.

Allerdings hat der Counting Bloom Filter auch Nachteile. Der Speicherverbrauch ist deutlich höher, da statt eines einzelnen Bits nun 4 Bits pro Position benötigt werden. Bei gleicher Genauigkeit benötigt ein Counting Bloom Filter somit ungefähr das Drei- bis Vierfache an Speicher im Vergleich zum klassischen Bloom-Filter. 
Außerdem können die Zähler überlaufen. Wenn mehr als 15 Elemente auf dieselbe Position hashen, reichen 4 Bits nicht mehr aus. Man könnte größere Zähler verwenden, allerdings würde das den Speicherbedarf weiter erhöhen. 
Der Counting Bloom Filter eignet sich daher besonders dann, wenn häufig gelöscht werden muss - man bezahlt diese Möglichkeit jedoch mit einem deutlich höheren Speicherverbrauch. An Verbesserungen wird zwar gearbeitet, doch eine genauere Betrachtung würde den Rahmen dieser Arbeit sprengen.\cite{CountingThiele}

\subsection{Größenplanung}
Ein weiteres grundlegendes Problem klassischer Bloom-Filter ist die Größenplanung. In der Regel muss man vorher festlegen, wie groß der Filter sein soll. Ist er zu klein dimensioniert, steigt die Fehlerwahrscheinlichkeit stark an. Die Bits werden sehr schnell gesetzt und die False-Positive-Rate nimmt deutlich zu. Ist der Filter hingegen zu groß gewählt, wird Speicherplatz verschwende, da möglicherweise Kapazitäten reserviert werden, die nie vollständig genutzt werden.

Der Scalable Bloom Filter bietet hier eine Lösung durch dynamisches Wachstum. \cite{bloomThiele}Er besteht aus mehreren klassischen Bloom Filtern, die nacheinander erstellt werden. Sobald ein Filter eine bestimmte Auslastung erreicht, wird ein neuer, größerer Filter mit eineer strengeren Fehlerrate hinzugefügt. Auf diese Weise bleibt die Gesamtfehlerwahrscheinlichkeit über alle Filter hinweg kontrollierbar. Selbst wenn mehrere Filter hinzukommen, bleibt die kombinierte Fehlerrate in akzeptablen Grenzen. 
Der große Vorteil ist, dass der Filter beliebig wachsen kann, ohne komplett neu aufgebaut werden zu müssen. Ein Nachteil ist jedoch, dass Abfragen mit jedem zusätzlichen Filter etwas langsamer werden, da mehrere Filter überprüft werden müssen.
Neben Counting- und Scalable-Varianten gibt es noch viele weitere spezielle Varianten von Bloom-Filtern, die jedoch den Rahmen dieser Arbeit überschreiten würden.\cite{ScalableThiele}

\section{Cuckoo Filter}
Eine alternative Datenstruktur stellt der Cuckoo Filter dar. Hierbei handelt es sich nicht merh wirklich um einen Bloom-Filter, dennoch verfolgt er dasselbe Ziel: speichereffiziente Mengenabfragen bei geringen Fehlerraten. 
Der Cuckoo Filter basiert nicht auf einem Bit-Array, sondern auf einer Hash-Tabelle mit kleinen Fächern, sogenannten Buckets. In diesen Buckets werden Fingerabdrücke, sogenannte Fingerprints, gespeichert. Das sind kurze, eindeutige Kennungen der Elemente mit nur wenigen Bits Länge.

Beim Einfügen eines Elements wird mithilfe einer Hash-Funktion berechnet, in welches Fach es gehört. Jedes Element besitzt dabei genau zwei mögliche Buckets, in denen es abgelegt werden kann. Ist in einem dieser Buckets noch Platz vorhanden, wird der Fingerprint dort gespeichert. Sind jedoch beide Buckets belegt, greift das sogenannte Cuckoo-Prinzip. Hier verdrängt das neue Element einen bestehenden Eintrag aus einem der beiden Buckets. Das verdrängte Element muss sich anschließend einen neuen Platz in seinem alternativen Bucket suchen. Dieser Prozess kann sich fortsetzen, bis schließlich alle Elemente einen Platz gefunden haben.

Der Cuckoo Filter bringt sowohl Vorteile als auch Nachteile mit sich. Ein großer Vorteil ist, dass Elemente problemlos gelöscht werden können, da die Fingerprints direkt gespeichert sind und gezielt entfernt werden können. 
Außerdem sind Abfragen sehr schnell, da nur zwei Buckets geprüft werden müssen.
Ein Nachteil zeigt sich bei sehr hoher Auslastung der Hash-Tabelle. In solchen Fällen kann die Verdrängungskette sehr lang werden, ohne dass ein freier Platz gefunden wird. Dann muss die gesamte Struktur vergrößert werden. 
Studien zeigen jedoch, dass Cuckoo Filter in vielen realen Anwendungen praktisch besser abschneiden als klassische Bloom-Filter.\cite{CuckooThiele}
Klassische Bloom-Filter sind dennoch besonders sinnvoll, wenn sehr große Datenmengen verarbeitet werden, der verfügbare Speicher knapp oder teuer ist, kleine Fehlerraten akzeptiert werden können und sie als Vorfilter von aufwendigen oder rechenintensiven Operationen eingesetzt werden. \cite{Broder01012004}